# 1.6 Оптимальное различение сигналов

## Средний риск в задаче различения
$$ \tag{1.6.2, стр. 116}
    r = r_{12}P(A_1H_2) + r_{21}P(A_2H_1) = r_{12}P(H_2)P(A_1|H_2) + r_{21}P(H_1)P(A_2|H_1)
$$
В бинарном коде обычно полагают $P(H_1) = P(H_2) = 0,5$. Как правило используется простая функция потерь с $r_{12} = r_{21}$. Тогда средний риск будет
$$ \tag{1.6.3, стр. 117}
    r = \frac{1}{2}[P(A_1|H_1) + P(A_2|H_1)] = p_{ош}
$$

---

## Симметричный канал
Если в канале передачи информации при выделении в приемном устройстве всех $m$ информационных символов имеют место одинаковые вероятности ошибок, то такой канал передачи информации называется симметричным.

---

## Критерий идеального наблюдателя
Условие минимума суммарной вероятности ошибки $p_{ош} \to \text{min}$ называется критерием идеального наблюдателя.

---

## Достаточная статистика и решающее правило в задаче различения
Достаточной статистикой являются $P(H_1)W[z(t)|\lambda_1]$ и $P(H_2)W[z(t)|\lambda_2]$. Решающее правило будет иметь вид

$$ \tag{1.6.4, стр. 118}
    P(H_1)W[z(t)|\lambda_1] \gtrless P(H_2)W[z(t)|\lambda_2]
$$

при $P(H_1) = P(H_2)$

$$ \tag{1.6.6, стр. 119}
    W[z(t)|\lambda_1] \gtrless W[z(t)|\lambda_2]
$$

и оптимальная оценка является оценкой максимального правдоподобия

При функции правдоподобия $(1.3.17)$ решающее правило будет

$$ \tag{1.6.8, стр. 120}
    Y_1 - \frac{E_{c1}}{2} \gtrless Y_2 - \frac{E_{c2}}{2}
$$

---

## Различение нулевого и ненулевого сигналов
При различении нулевого $S(t, \lambda_2)$ и ненулевого сигнала $S(t, \lambda_1) = S(t)$ решающее правило будет

$$ \tag{1.6.9, стр. 121}
    Y \gtrless \frac{E_c}{2}
$$

где $Y = \intop_0^{\Delta T}z(t)S(t)dt$, $E_c = \intop_0^{\Delta T}S^2(t)dt$
Решение задачи различения сигнала аналогично решению задачи обнаружения сигнала.

---

## Различение сигналов с одинаковой энергией
Решающее правило при различении сигналов с одинаковой энергией будет

$$ \tag{1.6.10, стр. 123}
    Y_1 \gtrless Y_2
$$

где $Y_i = \intop_0^{\Delta T}z(t)S(t|\lambda_i)dt, i = 1, 2$.

Различение двух сигналов можно реализовать либо в двух каналах обработки, либо в одном, через разность.

$$ \tag{1.6.11, стр. 124}
    Y_1 - Y_2 = \intop_0^{\Delta T}z(t)\left[S(t|\lambda_1) - S(t|\lambda_2)\right]dt \gtrless 0
$$

---

## Различение противоположных сигналов с одинаковой энергией
Как пример ФМ сигнал с фазой $0$ и $\pi$.
Решающее правило будет

$$ \tag{1.6.12, стр. 125}
    Y \gtrless 0
$$

---

## Различение сигналов в неизвестной начальной фазой
Решающие правила и схемы не меняются, но вместо корреляционного интеграла $Y[z(t)S(t)]$ используется огибающая корреляционного интеграла $Y[\dot{z}^*(t)\dot{S(t)}]$.

---

## Оценка при наличии неинформативного параметра
Для получения оптимальной оценки информативного параметра принимаемого сигнала при наличии у него неизвестных неинформативных параметров необходимо либо усреднять по ним функцию правдоподобия, либо осуществлять их оценивание и использовать полученные оценки при оценке информативного параметра.

---

## Вероятности ошибок при различении нулевого и ненулевого сигнала
$p_{ош} = \frac{1}{2}\left(p_{01} + p_{02}\right)$

$$ \tag{1.6.13, стр. 130}
    p_{01} = P\left(\intop_0^{\Delta T}[S(t) + n(t)]S(t)dt < \frac{E_c}{2} \right)
$$

$$ \tag{1.6.13, стр. 130}
    p_{02} = P\left(\intop_0^{\Delta T}n(t)S(t)dt > \frac{E_c}{2} \right)
$$

Для гауссовых плотностей распределения вероятностей $W_1(Y) = W(Y|H_1)$, $W_2(Y) = W(Y|H_2)$.

$$ \tag{1.6.14, стр. 131}
    p_{ош} = \frac{1}{2} \left[1 - Ф_0\left(\sqrt{\frac{q}{2}} \right) \right]
$$

где $q = E_c/N_0$ - отношение сигнал/шум,

$$
    Ф_0(x) = \sqrt{\frac{2}{\pi}}\intop_0^x exp\left(-\frac{t^2}{2}\right)dt
$$

функция Крампа.

---

## Вероятности ошибок при различении сигналов с одинаковой энергией

$$ \tag{1.6.15, стр. 131}
    p_{01} = P\left(\intop_0^{\Delta T}[S(t, \lambda_1) + n(t)]S(t, \lambda_1)dt < \intop_0^{\Delta T}[S(t, \lambda_2) + n(t)]S(t, \lambda_1)dt \right)
$$

$$ \tag{1.6.15, стр. 131}
    p_{02} = P\left(\intop_0^{\Delta T}[S(t, \lambda_2) + n(t)]S(t, \lambda_2)dt < \intop_0^{\Delta T}[S(t, \lambda_1) + n(t)]S(t, \lambda_2)dt \right)
$$

Для гауссовых плотностей распределения вероятностей $W_1(Y) = W(Y|H_1)$, $W_2(Y) = W(Y|H_2)$.

$$ \tag{1.6.16, стр. 131}
    p_{ош} = \frac{1}{2} \left[1 - Ф_0\left(\sqrt{q(1 - \rho)} \right) \right]
$$

$\rho = \frac{1}{E_c}\intop_0^{\Delta T}S(t, \lambda_1)S(t, \lambda_2)dt$ - коэффициент корреляции различаемых сигналов

Для ортогональных сигналов (ЧМ) $\rho = 1$

$$ \tag{1.6.17, стр. 132}
    p_{ош} = \frac{1}{2} \left[1 - Ф_0\left(\sqrt{q} \right) \right]
$$

Для противоположных сигналов (ФМ с фазой $0$ и $\pi$) $\rho = -1$

$$ \tag{1.6.18, стр. 132}
    p_{ош} = \frac{1}{2} \left[1 - Ф_0\left(\sqrt{2q} \right) \right]
$$

---

## Различение сигналов с неизвестной начальной фазой в условиях белого гауссова шума
$W_1(Y)$, $W_2(Y)$ при наличии сигнала будут соответствовать закону Релея-Райса с $m_Y = E_c$ и $\sigma_Y^2 = N_0E_c$. При отсутствии сигнала по закону Релея.

Аппроксимация вероятности ошибки будет иметь вид для различения нулевого и ненулевого сигнала

$$ \tag{1.6.19, стр. 134}
    p_{ош} = \frac{1}{2} \text{exp}\left(-\frac{q}{4}\right)
$$

Для различения ортогональных сигналов

$$ \tag{1.6.20, стр. 134}
    p_{ош} = \frac{1}{2} \text{exp}\left(-\frac{q}{2}\right)
$$

Для различения противоположных сигналов

$$ \tag{1.6.21, стр. 134}
    p_{ош} = \frac{1}{2} \text{exp}\left(-q\right)
$$
